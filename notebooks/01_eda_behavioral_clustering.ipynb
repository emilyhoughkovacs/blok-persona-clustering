{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis: Olist E-Commerce Dataset\n",
    "\n",
    "**Objective**: Understand the data structure, quality, and behavioral patterns to inform customer clustering for persona-based behavioral simulation.\n",
    "\n",
    "## Dataset Overview\n",
    "\n",
    "The Olist Brazilian E-Commerce dataset contains ~100K orders from 2016-2018 across 9 relational tables:\n",
    "- Customer demographics and identifiers\n",
    "- Order transactions with timestamps and status\n",
    "- Line-item details (products, prices, freight)\n",
    "- Payment information (method, installments)\n",
    "- Customer reviews and ratings\n",
    "- Product catalog with categories\n",
    "- Seller information\n",
    "- Geographic coordinates by ZIP code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Style settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "DATA_DIR = Path('../data/raw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all datasets\n",
    "customers = pd.read_csv(DATA_DIR / 'olist_customers_dataset.csv')\n",
    "\n",
    "orders = pd.read_csv(\n",
    "    DATA_DIR / 'olist_orders_dataset.csv',\n",
    "    parse_dates=['order_purchase_timestamp', 'order_approved_at',\n",
    "                 'order_delivered_carrier_date', 'order_delivered_customer_date',\n",
    "                 'order_estimated_delivery_date']\n",
    ")\n",
    "\n",
    "order_items = pd.read_csv(\n",
    "    DATA_DIR / 'olist_order_items_dataset.csv',\n",
    "    parse_dates=['shipping_limit_date']\n",
    ")\n",
    "\n",
    "payments = pd.read_csv(DATA_DIR / 'olist_order_payments_dataset.csv')\n",
    "\n",
    "reviews = pd.read_csv(\n",
    "    DATA_DIR / 'olist_order_reviews_dataset.csv',\n",
    "    parse_dates=['review_creation_date', 'review_answer_timestamp']\n",
    ")\n",
    "\n",
    "products = pd.read_csv(DATA_DIR / 'olist_products_dataset.csv')\n",
    "\n",
    "sellers = pd.read_csv(DATA_DIR / 'olist_sellers_dataset.csv')\n",
    "\n",
    "geolocation = pd.read_csv(DATA_DIR / 'olist_geolocation_dataset.csv')\n",
    "\n",
    "category_translation = pd.read_csv(DATA_DIR / 'product_category_name_translation.csv')\n",
    "\n",
    "print('All datasets loaded successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Profiling\n",
    "\n",
    "### 2.1 Profiling Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_dataset(df, name):\n",
    "    \"\"\"Generate comprehensive profile for a dataframe.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"DATASET: {name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Rows: {len(df):,}\")\n",
    "    print(f\"Columns: {len(df.columns)}\")\n",
    "    print(f\"Memory: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    print(f\"Duplicate rows: {df.duplicated().sum():,}\")\n",
    "    print(f\"\\nColumn Details:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    col_stats = []\n",
    "    for col in df.columns:\n",
    "        non_null = df[col].notna().sum()\n",
    "        null_count = df[col].isna().sum()\n",
    "        null_pct = df[col].isna().mean() * 100\n",
    "        \n",
    "        # Check for empty strings in object columns\n",
    "        empty_str = 0\n",
    "        if df[col].dtype == 'object':\n",
    "            empty_str = (df[col] == '').sum()\n",
    "        \n",
    "        col_stats.append({\n",
    "            'column': col,\n",
    "            'dtype': str(df[col].dtype),\n",
    "            'non_null': non_null,\n",
    "            'null_count': null_count,\n",
    "            'null_pct': null_pct,\n",
    "            'empty_str': empty_str,\n",
    "            'unique': df[col].nunique()\n",
    "        })\n",
    "    \n",
    "    stats_df = pd.DataFrame(col_stats)\n",
    "    print(stats_df.to_string(index=False))\n",
    "    return stats_df\n",
    "\n",
    "# Store all profiles\n",
    "profiles = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Customers Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles['customers'] = profile_dataset(customers, 'olist_customers_dataset.csv')\n",
    "print(\"\\nSample rows:\")\n",
    "display(customers.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Orders Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles['orders'] = profile_dataset(orders, 'olist_orders_dataset.csv')\n",
    "print(\"\\nSample rows:\")\n",
    "display(orders.head(3))\n",
    "print(\"\\nOrder status distribution:\")\n",
    "print(orders['order_status'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Order Items Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles['order_items'] = profile_dataset(order_items, 'olist_order_items_dataset.csv')\n",
    "print(\"\\nSample rows:\")\n",
    "display(order_items.head(3))\n",
    "print(\"\\nPrice statistics:\")\n",
    "print(order_items[['price', 'freight_value']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Payments Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles['payments'] = profile_dataset(payments, 'olist_order_payments_dataset.csv')\n",
    "print(\"\\nSample rows:\")\n",
    "display(payments.head(3))\n",
    "print(\"\\nPayment type distribution:\")\n",
    "print(payments['payment_type'].value_counts())\n",
    "print(\"\\nInstallments distribution:\")\n",
    "print(payments['payment_installments'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Reviews Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles['reviews'] = profile_dataset(reviews, 'olist_order_reviews_dataset.csv')\n",
    "print(\"\\nSample rows:\")\n",
    "display(reviews.head(3))\n",
    "print(\"\\nReview score distribution:\")\n",
    "print(reviews['review_score'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Products Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles['products'] = profile_dataset(products, 'olist_products_dataset.csv')\n",
    "print(\"\\nSample rows:\")\n",
    "display(products.head(3))\n",
    "\n",
    "# Merge with translations\n",
    "products = products.merge(category_translation, on='product_category_name', how='left')\n",
    "print(\"\\nTop 10 product categories (English):\")\n",
    "print(products['product_category_name_english'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 Sellers Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles['sellers'] = profile_dataset(sellers, 'olist_sellers_dataset.csv')\n",
    "print(\"\\nSample rows:\")\n",
    "display(sellers.head(3))\n",
    "print(\"\\nTop seller states:\")\n",
    "print(sellers['seller_state'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.9 Geolocation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles['geolocation'] = profile_dataset(geolocation, 'olist_geolocation_dataset.csv')\n",
    "print(\"\\nSample rows:\")\n",
    "display(geolocation.head(3))\n",
    "print(f\"\\nUnique ZIP prefixes: {geolocation['geolocation_zip_code_prefix'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Missing Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprehensive_missing_analysis(df, name):\n",
    "    \"\"\"Detect all forms of missing values.\"\"\"\n",
    "    null_patterns = ['', ' ', 'NULL', 'null', 'None', 'N/A', 'n/a', 'NA', '-']\n",
    "    \n",
    "    results = []\n",
    "    for col in df.columns:\n",
    "        pandas_null = df[col].isna().sum()\n",
    "        empty_str = 0\n",
    "        whitespace = 0\n",
    "        \n",
    "        if df[col].dtype == 'object':\n",
    "            empty_str = (df[col] == '').sum()\n",
    "            whitespace = df[col].astype(str).str.strip().eq('').sum() - empty_str - pandas_null\n",
    "            whitespace = max(0, whitespace)\n",
    "        \n",
    "        total = pandas_null + empty_str + whitespace\n",
    "        results.append({\n",
    "            'column': col,\n",
    "            'pandas_null': pandas_null,\n",
    "            'empty_string': empty_str,\n",
    "            'whitespace': whitespace,\n",
    "            'total_missing': total,\n",
    "            'pct_missing': total / len(df) * 100\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Analyze key datasets\n",
    "print(\"Missing Data Analysis\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for name, df in [('orders', orders), ('reviews', reviews), ('products', products)]:\n",
    "    missing = comprehensive_missing_analysis(df, name)\n",
    "    missing_cols = missing[missing['total_missing'] > 0]\n",
    "    if len(missing_cols) > 0:\n",
    "        print(f\"\\n{name.upper()} - Columns with missing data:\")\n",
    "        print(missing_cols.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers_iqr(df, columns, threshold=1.5):\n",
    "    \"\"\"Detect outliers using IQR method.\"\"\"\n",
    "    results = []\n",
    "    for col in columns:\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - threshold * IQR\n",
    "        upper = Q3 + threshold * IQR\n",
    "        outliers = df[(df[col] < lower) | (df[col] > upper)]\n",
    "        results.append({\n",
    "            'column': col,\n",
    "            'min': df[col].min(),\n",
    "            'Q1': Q1,\n",
    "            'median': df[col].median(),\n",
    "            'Q3': Q3,\n",
    "            'max': df[col].max(),\n",
    "            'IQR': IQR,\n",
    "            'lower_bound': lower,\n",
    "            'upper_bound': upper,\n",
    "            'outlier_count': len(outliers),\n",
    "            'outlier_pct': len(outliers) / len(df) * 100\n",
    "        })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Check order_items\n",
    "print(\"Order Items - Outlier Analysis\")\n",
    "print(\"=\"*60)\n",
    "outliers_items = detect_outliers_iqr(order_items, ['price', 'freight_value'])\n",
    "print(outliers_items.to_string(index=False))\n",
    "\n",
    "# Check payments\n",
    "print(\"\\n\\nPayments - Outlier Analysis\")\n",
    "print(\"=\"*60)\n",
    "outliers_payments = detect_outliers_iqr(payments, ['payment_value', 'payment_installments'])\n",
    "print(outliers_payments.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualizations\n",
    "\n",
    "### 5.1 Price and Freight Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Price distribution\n",
    "axes[0, 0].hist(order_items['price'], bins=50, edgecolor='white', alpha=0.7)\n",
    "axes[0, 0].set_xlabel('Price (BRL)')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].set_title('Price Distribution (Linear Scale)')\n",
    "\n",
    "axes[0, 1].hist(order_items['price'], bins=50, edgecolor='white', alpha=0.7)\n",
    "axes[0, 1].set_xscale('log')\n",
    "axes[0, 1].set_xlabel('Price (BRL, log scale)')\n",
    "axes[0, 1].set_title('Price Distribution (Log Scale)')\n",
    "\n",
    "# Freight distribution\n",
    "axes[1, 0].hist(order_items['freight_value'], bins=50, edgecolor='white', alpha=0.7, color='orange')\n",
    "axes[1, 0].set_xlabel('Freight Value (BRL)')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].set_title('Freight Value Distribution')\n",
    "\n",
    "# Price vs Freight scatter\n",
    "sample = order_items.sample(min(5000, len(order_items)), random_state=42)\n",
    "axes[1, 1].scatter(sample['price'], sample['freight_value'], alpha=0.3, s=10)\n",
    "axes[1, 1].set_xlabel('Price (BRL)')\n",
    "axes[1, 1].set_ylabel('Freight Value (BRL)')\n",
    "axes[1, 1].set_title('Price vs Freight (sampled)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/price_freight_distributions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Payment Type and Installments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Payment type\n",
    "payment_counts = payments['payment_type'].value_counts()\n",
    "colors = sns.color_palette('husl', len(payment_counts))\n",
    "axes[0].bar(payment_counts.index, payment_counts.values, color=colors)\n",
    "axes[0].set_xlabel('Payment Type')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Payment Type Distribution')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Installments\n",
    "installment_counts = payments['payment_installments'].value_counts().sort_index()\n",
    "installment_counts = installment_counts[installment_counts.index <= 12]  # Focus on 1-12\n",
    "axes[1].bar(installment_counts.index, installment_counts.values, color='teal')\n",
    "axes[1].set_xlabel('Number of Installments')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('Installments Distribution (1-12)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/payment_distributions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Review Score Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "review_counts = reviews['review_score'].value_counts().sort_index()\n",
    "colors = ['#d73027', '#fc8d59', '#fee08b', '#d9ef8b', '#1a9850']  # Red to green\n",
    "ax.bar(review_counts.index, review_counts.values, color=colors, edgecolor='white')\n",
    "ax.set_xlabel('Review Score')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Review Score Distribution')\n",
    "ax.set_xticks([1, 2, 3, 4, 5])\n",
    "\n",
    "# Add percentages\n",
    "total = review_counts.sum()\n",
    "for i, (score, count) in enumerate(review_counts.items()):\n",
    "    ax.annotate(f'{count/total*100:.1f}%', (score, count), ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/review_score_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Order Status and Timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Order status\n",
    "status_counts = orders['order_status'].value_counts()\n",
    "axes[0].barh(status_counts.index, status_counts.values, color='steelblue')\n",
    "axes[0].set_xlabel('Count')\n",
    "axes[0].set_title('Order Status Distribution')\n",
    "\n",
    "# Orders over time\n",
    "orders_by_month = orders.set_index('order_purchase_timestamp').resample('M').size()\n",
    "axes[1].plot(orders_by_month.index, orders_by_month.values, marker='o', linewidth=2)\n",
    "axes[1].set_xlabel('Date')\n",
    "axes[1].set_ylabel('Number of Orders')\n",
    "axes[1].set_title('Orders Over Time (Monthly)')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/order_status_timeline.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Product Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Get top 20 categories\n",
    "top_categories = products['product_category_name_english'].value_counts().head(20)\n",
    "ax.barh(top_categories.index[::-1], top_categories.values[::-1], color='coral')\n",
    "ax.set_xlabel('Number of Products')\n",
    "ax.set_title('Top 20 Product Categories')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/top_categories.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Customer-Level Analysis\n",
    "\n",
    "First, let's understand the relationship between `customer_id` and `customer_unique_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Customer ID Analysis\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total customer_id entries: {len(customers):,}\")\n",
    "print(f\"Unique customer_id: {customers['customer_id'].nunique():,}\")\n",
    "print(f\"Unique customer_unique_id: {customers['customer_unique_id'].nunique():,}\")\n",
    "\n",
    "# How many orders per unique customer?\n",
    "orders_per_customer = customers.groupby('customer_unique_id').size()\n",
    "print(f\"\\nOrders per unique customer:\")\n",
    "print(orders_per_customer.describe())\n",
    "print(f\"\\nRepeat customers (>1 order): {(orders_per_customer > 1).sum():,} ({(orders_per_customer > 1).mean()*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Orders per customer histogram\n",
    "axes[0].hist(orders_per_customer.values, bins=range(1, 20), edgecolor='white', align='left')\n",
    "axes[0].set_xlabel('Number of Orders')\n",
    "axes[0].set_ylabel('Number of Customers')\n",
    "axes[0].set_title('Purchase Frequency Distribution')\n",
    "axes[0].set_xticks(range(1, 20))\n",
    "\n",
    "# Customer state distribution\n",
    "customer_states = customers.drop_duplicates('customer_unique_id')['customer_state'].value_counts().head(10)\n",
    "axes[1].bar(customer_states.index, customer_states.values, color='purple')\n",
    "axes[1].set_xlabel('State')\n",
    "axes[1].set_ylabel('Number of Unique Customers')\n",
    "axes[1].set_title('Top 10 Customer States')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/customer_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7 Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge key numeric features for correlation\n",
    "correlation_df = order_items[['order_id', 'price', 'freight_value']].merge(\n",
    "    payments[['order_id', 'payment_value', 'payment_installments']].groupby('order_id').agg({\n",
    "        'payment_value': 'sum',\n",
    "        'payment_installments': 'mean'\n",
    "    }).reset_index(),\n",
    "    on='order_id'\n",
    ")\n",
    "\n",
    "# Add review score\n",
    "correlation_df = correlation_df.merge(\n",
    "    reviews[['order_id', 'review_score']],\n",
    "    on='order_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Calculate correlation matrix\n",
    "numeric_cols = ['price', 'freight_value', 'payment_value', 'payment_installments', 'review_score']\n",
    "corr_matrix = correlation_df[numeric_cols].corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='RdBu_r', center=0, fmt='.2f', \n",
    "            square=True, linewidths=0.5, ax=ax)\n",
    "ax.set_title('Correlation Matrix of Order-Level Features')\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/correlation_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.8 Delivery Time Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate delivery metrics for delivered orders\n",
    "delivered = orders[orders['order_status'] == 'delivered'].copy()\n",
    "delivered['delivery_days'] = (delivered['order_delivered_customer_date'] - delivered['order_purchase_timestamp']).dt.days\n",
    "delivered['delivery_delta'] = (delivered['order_delivered_customer_date'] - delivered['order_estimated_delivery_date']).dt.days\n",
    "\n",
    "print(\"Delivery Time Analysis (Delivered Orders Only)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total delivered orders: {len(delivered):,}\")\n",
    "print(f\"\\nDelivery days statistics:\")\n",
    "print(delivered['delivery_days'].describe())\n",
    "print(f\"\\nDelivery delta (actual - estimated):\")\n",
    "print(delivered['delivery_delta'].describe())\n",
    "print(f\"\\nEarly deliveries: {(delivered['delivery_delta'] < 0).sum():,} ({(delivered['delivery_delta'] < 0).mean()*100:.1f}%)\")\n",
    "print(f\"On-time deliveries: {(delivered['delivery_delta'] == 0).sum():,} ({(delivered['delivery_delta'] == 0).mean()*100:.1f}%)\")\n",
    "print(f\"Late deliveries: {(delivered['delivery_delta'] > 0).sum():,} ({(delivered['delivery_delta'] > 0).mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Delivery days histogram\n",
    "axes[0].hist(delivered['delivery_days'].dropna(), bins=50, edgecolor='white', alpha=0.7)\n",
    "axes[0].axvline(delivered['delivery_days'].median(), color='red', linestyle='--', label=f'Median: {delivered[\"delivery_days\"].median():.0f} days')\n",
    "axes[0].set_xlabel('Delivery Days')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Delivery Time Distribution')\n",
    "axes[0].legend()\n",
    "\n",
    "# Delivery delta histogram\n",
    "delta_clipped = delivered['delivery_delta'].clip(-30, 30)  # Clip extremes for visualization\n",
    "axes[1].hist(delta_clipped.dropna(), bins=60, edgecolor='white', alpha=0.7, color='orange')\n",
    "axes[1].axvline(0, color='green', linestyle='--', linewidth=2, label='On-time')\n",
    "axes[1].set_xlabel('Days (Actual - Estimated)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Delivery Delta Distribution (clipped to Â±30 days)')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/delivery_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.9 Review Score vs Delivery Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge delivery data with reviews\n",
    "delivery_reviews = delivered.merge(reviews[['order_id', 'review_score']], on='order_id', how='inner')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Box plot: review score by delivery status\n",
    "delivery_reviews['delivery_status'] = pd.cut(\n",
    "    delivery_reviews['delivery_delta'],\n",
    "    bins=[-np.inf, -1, 0, np.inf],\n",
    "    labels=['Early', 'On-time', 'Late']\n",
    ")\n",
    "\n",
    "sns.boxplot(data=delivery_reviews, x='delivery_status', y='review_score', ax=axes[0], palette='RdYlGn')\n",
    "axes[0].set_xlabel('Delivery Status')\n",
    "axes[0].set_ylabel('Review Score')\n",
    "axes[0].set_title('Review Score by Delivery Status')\n",
    "\n",
    "# Average review score by delivery delta\n",
    "delta_review = delivery_reviews.groupby(delivery_reviews['delivery_delta'].clip(-10, 20))['review_score'].mean()\n",
    "axes[1].plot(delta_review.index, delta_review.values, marker='o', linewidth=2)\n",
    "axes[1].axvline(0, color='green', linestyle='--', alpha=0.5)\n",
    "axes[1].set_xlabel('Delivery Delta (days)')\n",
    "axes[1].set_ylabel('Average Review Score')\n",
    "axes[1].set_title('Average Review Score by Delivery Delta')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/delivery_vs_reviews.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATASET SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "datasets_summary = [\n",
    "    ('customers', customers, 'Customer master data with unique customer IDs'),\n",
    "    ('orders', orders, 'Order transactions with timestamps and status'),\n",
    "    ('order_items', order_items, 'Line-item details (products, prices, freight)'),\n",
    "    ('payments', payments, 'Payment transactions (type, installments, value)'),\n",
    "    ('reviews', reviews, 'Customer reviews and ratings'),\n",
    "    ('products', products, 'Product catalog with categories'),\n",
    "    ('sellers', sellers, 'Seller information and location'),\n",
    "    ('geolocation', geolocation, 'Geographic coordinates by ZIP code'),\n",
    "]\n",
    "\n",
    "for name, df, desc in datasets_summary:\n",
    "    print(f\"\\n{name.upper()}:\")\n",
    "    print(f\"  Description: {desc}\")\n",
    "    print(f\"  Rows: {len(df):,}\")\n",
    "    print(f\"  Columns: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Engineering Recommendations\n",
    "\n",
    "Based on the EDA, here are the recommended features for behavioral clustering:\n",
    "\n",
    "### RFM Features\n",
    "- `recency_days`: Days since last purchase\n",
    "- `frequency`: Number of orders per customer\n",
    "- `monetary_total`: Total lifetime spend\n",
    "- `monetary_avg`: Average order value\n",
    "- `tenure_days`: Days between first and last purchase\n",
    "\n",
    "### Payment Behavior\n",
    "- `pct_credit_card`: % of orders paid by credit card\n",
    "- `pct_boleto`: % of orders paid by boleto\n",
    "- `avg_installments`: Average number of installments\n",
    "- `installment_rate`: % of orders with >1 installment\n",
    "\n",
    "### Category Preferences\n",
    "- `category_diversity`: Number of distinct categories purchased\n",
    "- `category_hhi`: Herfindahl concentration index (0=diverse, 1=concentrated)\n",
    "- `avg_product_price`: Mean unit price of purchases\n",
    "- `pct_high_price`: % of orders above median price\n",
    "\n",
    "### Review/Satisfaction\n",
    "- `avg_review_score`: Mean review score\n",
    "- `review_variance`: Variance in review scores\n",
    "- `review_rate`: % of orders with reviews\n",
    "- `has_comment_rate`: % of reviews with comments\n",
    "\n",
    "### Delivery Experience\n",
    "- `avg_delivery_days`: Mean delivery time\n",
    "- `avg_delivery_delta`: Mean (actual - estimated) delivery\n",
    "- `pct_late_delivery`: % of orders delivered late"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Scaling Recommendations\n",
    "\n",
    "For k-means clustering, all features should be standardized (mean=0, std=1) using `StandardScaler`.\n",
    "\n",
    "**Pre-scaling transformations:**\n",
    "- **Log transform** for right-skewed monetary features: `monetary_total`, `monetary_avg`, `avg_product_price`\n",
    "- **No additional transform** for: percentages, scores, counts\n",
    "\n",
    "**Implementation:**\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Log transform skewed features\n",
    "for col in ['monetary_total', 'monetary_avg', 'avg_product_price']:\n",
    "    features[f'{col}_log'] = np.log1p(features[col])\n",
    "\n",
    "# Standardize all features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(features[feature_columns])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Data Quality Notes\n",
    "\n",
    "### Missing Data\n",
    "- **Reviews**: `review_comment_title` (87% missing), `review_comment_message` (58% missing) - Most customers don't leave text comments\n",
    "- **Orders**: Delivery timestamps missing for non-delivered orders (~3% of orders)\n",
    "- **Products**: `product_category_name` missing for 610 products (1.9%)\n",
    "\n",
    "### Outliers\n",
    "- **Price**: Range R$0.85 - R$6,735, with heavy right skew. Consider log transform or capping at 99th percentile\n",
    "- **Freight**: Range R$0 - R$409, also right-skewed\n",
    "- **Installments**: 1-24, with 52% being single payment\n",
    "\n",
    "### Key Observations\n",
    "1. **Low repeat rate**: Only ~3% of customers have >1 order - most behavioral features will be based on single transactions\n",
    "2. **Strong delivery-satisfaction link**: Late deliveries correlate with lower review scores\n",
    "3. **Credit card dominance**: 74% of payments are credit card\n",
    "4. **Positive review bias**: 57% of reviews are 5-star"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
